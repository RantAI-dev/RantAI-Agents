services:
  postgres:
    image: postgres:16
    container_name: rantai-agents-postgres
    restart: unless-stopped
    environment:
      POSTGRES_USER: horizonlife
      POSTGRES_PASSWORD: horizonlife_secret
      POSTGRES_DB: horizonlife_insurance
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U horizonlife -d horizonlife_insurance"]
      interval: 10s
      timeout: 5s
      retries: 5

  surrealdb:
    image: surrealdb/surrealdb:latest
    container_name: rantai-agents-surrealdb
    restart: unless-stopped
    user: root
    command: start --user root --pass root file:/data/database.db
    ports:
      - "8000:8000"
    volumes:
      - surrealdb_data:/data
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8000/health || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5

  # S3-compatible object storage (RustFS)
  rustfs:
    image: rustfs/rustfs:latest
    container_name: rantai-agents-rustfs
    restart: unless-stopped
    ports:
      - "9000:9000"  # S3 API
      - "9001:9001"  # Web Console
    volumes:
      - rustfs_data:/data

  # Ollama for local OCR models
  # Supports: GLM-OCR, Moondream, MiniCPM-V, Qwen3-VL
  # Pull models with: docker exec -it rantai-agents-ollama ollama pull glm-ocr
  ollama:
    image: ollama/ollama:latest
    container_name: rantai-agents-ollama
    restart: unless-stopped
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
    # GPU support (uncomment if you have NVIDIA GPU)
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: all
    #           capabilities: [gpu]
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:11434/api/tags || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

volumes:
  postgres_data:
  surrealdb_data:
  rustfs_data:
  ollama_data:
